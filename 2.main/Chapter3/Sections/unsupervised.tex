\section{یادگیری نظارت نشده}

% generating states
در تمامی روش های قبل، ما از یادگیری نظارت شده برای آموزش مدل استفاده کردیم. یعنی برچسب داده ها را نیز داشتیم، و هدف بیشتر انجام پیش بینی با وجود تعداد کمتر آزمایش بود. در این قسمت ما از روش های یادگیری نظارت نشده استفاده می کنیم. که نیازی به دانستن برچسب داده ها ندارند. هرچند انتظار داریم که دقت این روش ها، از روش های نظارت شده به مقدار قابل توجهی کمتر باشد، اما این روش ها  برای تعمیم به ابعاد بالاتر که نمی توان به راحتی با معیاری مانند
\lr{PPT}
برچسب گذاری کرد، ارزشمند هستند. البته ما در این پایان نامه، ابعاد بالاتر را بررسی نکرده ایم، و این قسمت فقط به عنوان اثبات ایده
\LTRfootnote{Proof of Concept}
ارایه شده است.

ابتدا ما روش های کلاسیکی یادگیری نظارت نشده را بررسی کرده ایم. در این روش ها، فقط ۱۵ ستون اول داده که شامل ویژگی ها هستند استفاده شده، و هیچ استفاده ای از برچسب ها نشده است. همچنین در این روش ها، از توصیف کامل‌(هر ۱۵ ویژگی) ماتریس چگالی استفاده شده است، چرا که هدف ما در این بخش، پیش بینی با توصیف ناکامل نیست. نتایج این روش ها در جدول
\ref{tab:unsupervised}
آورده شده است. همانطور که مشاهده می شود، روش
\lr{OPTICS}
بیشترین صحت را بین این مدل ها به دست آورد.

\begin{center}\label{tab:unsupervised}
\begin{tabular}{|c|c|}
    \hline
    \rowcolor{LightCyan}
    \mc{1}{Unsupervised}  & \mc{1}{Accuracy} \\
    \hline
    K-means & 73\% \\
    \hline
    DBSCAN & 74\% \\
    \hline
    OPTICS  & 77\% \\
    \hline
    Birch & 68\% \\
    \hline
\end{tabular}
\end{center}
