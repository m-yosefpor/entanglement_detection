\section{شبکه های عصبی}

یکی دیگر از روش های یادگیری ماشینی، روش شبکه های عصبی
\LTRfootnote{Neural Networks}
و یادگیری عمیق
\LTRfootnote{Deep learning}
است. در ابتدا برای اینکه بفهمیم آیا این روش قادر به یادگیری بهینه با تعداد اندازه گیری کمتر است، این موضوع را بررسی می کنیم که آیا اصلا شبکه قادر است با داشتن هر ۱۵ اندازه گیری (توصیف کامل سیستم)، حالت های در هم تنیده و جداپذیر را از یکدیگر تفکیک کند یا خیر. در ادامه خواهیم دید که شبکه می تواند به طور تقریبا کامل، تمامی حالت های درهم تنیده و جداپذیر را از یکدیگر تفکیک کند.

\input{\figurePATH{3}{nn_full}}


معماری های متفاوتی از شبکه های عصبی برای یادگیری انجام شد و یکی از معماری هایی که بهترین نتیجه را منجر میشود در شکل
\ref{fig:nn_full}
آورده شده است. همانطور که مشاهده می شود، در این معماری در ابتدا تعداد گره های بیشتری استفاده شده،‌ و به مرور در لایه ها تعداد گره ها کمتر می شوند. تابع فعالسازی استفاده شده در این معماری تابع
\lr{ReLU}
است.

بعد از آموزش شبکه با ۸۰٪ از ۵ میلیون داده، ‌شبکه با ۲۰٪ داده های دیگر که مدل برچسب آن داده ها را ندیده است، آزمایش می شود و صحت برچسب پیش بینی شده با بر جسب واقعی مقایسه می شود. با این کار، مشاهده کردیم که مدل آموزش داده شده،‌ بیشتر از
۹۹٪
داده ها درست پیش بینی می کند.


اگرچه در ظاهر این پیش بینی حالت ها توسط ماشین، با توجه به داشتن معیر
\lr{PPT}
بدون ارزش افزوده ای بنظر می رسد، اما
نتیجه ی جالبی که از این مشاهده منجر می شود این است که ماشین بدون اینکه اطلاعی از معیار
\lr{PPT}
داشته باشد، فقط با دیدن نمونه هایی از حالت های در هم تنیده و جداپذیر، توانسته است این معیار یا معیاری هم ارز
\lr{PPT}
را بدست آورد که نتیجه ی حیرت انگیری است.
