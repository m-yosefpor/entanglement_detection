\section{یادگیری شبه نظارت شده}

در روش یادگیری شبه نظارت شده، برچسب همه ی داده ها مشخص نیست، بلکه فقط برخی از این داده ها برچسب دارند. تفاوت این روش با روش یادگیری نظارت نشده، این است که این روش ها از برچسب های موجود داده ها استفاده می کنند، و احتمالا منجر به دقت بالاتری نسبت به روش های نظارت نشده دارند. هرچند نسبت به روش های نظارت شده، همچنان انتظار دقت  کمتری را داریم.

این روش ها نیز برای تعمیم به ابعاد بالاتر بسیار مطلوب هستند. به این خاطر که می توان برخی از حالت های ابعاد بالاتر را با استفاده از شاهد ها و یا روش های دیگر برچسب گذاری کرد. مثلا معیار
\lr{PPT}
با توجه به اینکه یک شرط لازم، و یک شاهد در ابعاد بالاتر است، می تواند مقداری از حالت های در هم تنیده را تشخیص دهد. همچنین حالت های خالص را می توانیم با روش تجزیه اشمیت برچسب گذاری کنیم.

علاوه بر این، در این قسمت ما با روشی، مقدار نسبتا زیادی حالت جداپذیر تولید کرده ایم. روش کار به این صورت است که
ابتدا دو ماتریس چگالی تصادفی تولید می کنیم و آن ها را در هم ضرب تانسوری می کنیم. با این کار یک سری داده تولید می کنیم. سپس یک آرایه ی
$n$
عضوی در نظر می گیریم (‌ما در اینجا
$n=10$
انتخاب کردیم
)،
و ده عدد تصادفی تولید کرده و آن ها را به جمع آن ده عدد تقسیم می کنیم. به این صورت ده عدد متفاوت که جمع آن ها واحد می شود به دست آورده ایم. سپس با استفاده از این ده عدد، و ده ماتریس تولید شده از قسمت قبل، یک ترکیب خطی از این ماتریس ها میسازیم، که چون ترکیب خطی از ماتریس های جداپذیر هستند، ‌این ها نیز جداپذیرند. سپس با استفاده از این ماتریس های چگالی، می توانیم تمام پانزده ویژگی را محاسبه کنیم و به همه ی این داده ها برچسب جداپذیر بودن می زنیم و آن ها را ذخیره می کنیم.

در این بخش ما از تعدادی از روش های شبه نظارت شده استفاده کردیم، و نتایج این مدل ها در جدول
\ref{tab:semisupervised}
آورده ایم.

\subsection{روش تشخیص ناهنجاری}

یک روش یادگیری شبه نظارت شده دیگر روش تشخیص ناهنجاری است که با روش های شبه نظارت شده قبلی نسبتا متفاوت است. از این نظر که در این روش، با داشتن برچسب فقط یک نوع داده این کار صورت می گیرد. یعنی داده های مورد نیاز آموزش این مدل، همه فقط حالت های جداپذیر، و یا همه فقط حالت های درهم تنیده هستند. سپس اگر یک حالت جدید را بخواهیم پیش بینی کنیم،‌این روش با مقایسه با حالت های آموزش دیده شده، تصمیم میگیرد که آیا این مشابه داده های قبلی (و در نتیجه هم برچسب با آن) است یا اینکه یک ناهنجاری (و در نتیجه دارای برچسب متفاوت است).

در این جا ما از داده های جداپذیر که در قسمت قبل روش تولید آن ها رو توضیح دادیم، استفاده کرده و مدل را آموزش داده ایم. سپس مدل را با زیر مجموعه ای تصادفی از داده های اصلی که برچسب آن ها را نیز می دانیم، آزمایش کردیم. نتیجه به دست آمده در جدول
\ref{tab:semisupervised}
قابل مشاهده است.


\begin{center}\label{tab:semisupervised}
\begin{tabular}{|c|c|}
    \hline
    \rowcolor{LightCyan}
    \mc{1}{Semisupervised}  & \mc{1}{Accuracy} \\
    \hline
    \lr{Anomaly Detection} & 81\% \\
    \hline
    LabelPropagation & 64\% \\
    \hline
    LabelSpreading  & 67\% \\
    \hline
\end{tabular}
\end{center}

